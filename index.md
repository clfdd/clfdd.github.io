---
layout: post
---

> The workshop on Classifier Learning from Difficult Data is organized during the [International Conference on Computational Science ICCS 2020](https://www.iccs-meeting.org/iccs2020/) in Amsterdam, The Netherlands.

# About

Nowadays many practical decision task require to build models on the basis of data which included serious difficulties, as imbalanced class distributions, high number of classes, high-dimensional feature, small or extremely high number of learning examples, limited access to ground truth, data incompleteness, or data in motion, to enumerate only a few. Such characteristics may strongly deteriorate the final model performances. Therefore, the proposition of the new learning methods which can combat the mentioned above difficulties should be the focus of intense research.
The main aim of this workshop is to discuss the problems of data difficulties, to identify new issues, and to shape future directions for research.

# Online meeting

The joint sessions <em>“Classifier Learning from Difficult Data”</em> and <em>“Computational Methods for Emerging Problems in (dis-)Information Analysis </em>” will take place on June 4th, 2020. The CLD2 and DIS-A workshops will take place via the zoom.us platform. Joining will be possible 15 minutes before the start of the meeting, which is at 8:45 AM (GMT + 2).

<!--After the session we would like to rank the presentation – we will ask participants for their opinion and we would like to award 3 of them (using the waiver refund money – I will send you names , paper ids, and emails of the awarded presenters after the session):

- Best presentation award – 100 EURO
- 2x distinctions		75 EURO each -->

You can join via the following [hyperlink](https://pwr-edu.zoom.us/j/91255889567?pwd=K2c1Z0F4ZTA4b1JvZVgxZjlXRUVZdz09), or by using the *join a meeting* function and providing the following data:
- Meeting ID: 912 5588 9567

Passwords were sent directly to each of the conference participants.
If you have any questions, please contact [Paweł Ksieniewicz](mailto:pawel.ksieniewicz@pwr.edu.pl) or [Paweł Zyblewski](mailto:pawel.zyblewski@pwr.edu.pl).

Best regards and take care!

Michał Choraś and Michał Woźniak


# Meeting schedule

The meeting schedule of CLD2 and DIS-A workshops is as follows


| Time        | Event           |Paper ID|
| ------------- |:-------------|---:|
| 9:00 – 9:10 |	<strong>Invitation and opening <em>(Michał Choraś, Michał Woźniak)</em></strong> |
|9:10 – 10:00 |	<strong>Keynote talk <em>(chair:  Prof. Michał Woźniak)</em></strong>|
||<strong>Prof. Michal Choraś<br>Current challenges in ML/AI: security, explainability and fairness</strong>|
|10:20-12:00| <strong>Session 1 <em>(chair: Prof. Olgierd Unold)</em></strong>|
||Paweł Teisseyre, Jan Mielniczuk and Małgorzata Łazęcka<br> Different strategies of fitting logistic regression for positive and unlabelled data|97 |
||Dariusz Sychel, Przemysław Klęsk and Aneta Bera<br> Branch-and-Bound Search for Training Cascades of Classifiers|132|
||Mariusz Topolski<br> Application of the stochastic gradient method in the construction of the main components of PCA in the task diagnosis of multiple sclerosis in children|516|
||Wojciech Wieczorek, Olgierd Unold, Łukasz Strąk and Arkadiusz Nowakowski<br> Grammatical Inference by Answer Set Programming|128|
||Magda Friedjungová, Daniel Vašata, Maksym Balatsko and Marcel Jiřina<br> Missing Features Reconstruction Using a Wasserstein Generative Adversarial Imputation Network|192|
|12:20-14:00| <strong>Session 2 <em>(chair: Dr. Paweł Ksieniewicz)</em></strong>|
||Pawel Zyblewski and Michal Wozniak<br> Dynamic Classifier Selection for data with skewed class distribution using Imbalance Ratio and Euclidean distance|184|
||Jan Brabec, Tomas Komarek, Vojtech Franc and Lukas Machlica<br> On Model Evaluation under Non-constant Class Imbalance|237|
||Pawel Trajdos and Marek Kurzynski<br> A Correction Method of a Base Classifier Applied to Imbalanced Data Classification|347|
||Paweł Ksieniewicz<br> Standard Decision Boundary in a support-domain of fuzzy classifier prediction for the task of imbalanced data classification|359|
||Jakub Klikowski and Michal Wozniak<br> Employing One-class SVM Classifier Ensemble for Imbalanced Data Stream Classification|559|
|14:20-16:00| <strong>Session 3 <em>(chair: Prof. Tomasz Andrysiak)</em></strong>
||Paweł Ksieniewicz and Robert Burduk<br> Clustering and Weighted Scoring in Geometric Space Support Vector Machine Ensemble for Highly Imbalanced Data Classification|629|
||Michał Żak and Michał Woźniak<br> Performance Analysis of Binarization Strategies for Multi-Class Imbalanced Data Classification|661|
||Paweł Ksieniewicz, Róża Goścień, Mirosław Klinkowski and Krzysztof Walkowiak<br> Pattern recognition model to aid the optimization of Dynamic Spectrally-Spatially Flexible Optical Networks|639|
||Tomasz Andrysiak and Łukasz Saganowski<br> Maintenance and Security System for PLC Railway LED Sign Communication Infrastructure|490|
||Jakub Nowak, Taras Holotyak, Marcin Korytkowski, Rafal Scherer and Sviatsolav Voloshynovskiy<br> Behavioral Biometric User Authentication from URL Logs|522|
|16:20-18:00| <strong>Session 4 <em>(chair: Prof. Michał Choraś)</em></strong>
||Marek Pawlicki, Rafal Kozik and Witold Holubowicz<br> On the impact of network data balancing in cybersecurity applications|99|
||Sebastian Kula, Michał Choraś, Rafał Kozik, Pawel Ksieniewicz and Michał Wozniak<br> Sentiment Analysis for Fake News Detection by Means of Neural Networks|362|
||Roman Englert and Jörg Muschiol<br> Syntactic and Semantic Bias Detection and Countermeasures|25|
||Amir Ebrahimi Fard, Majid Mohammadi and Bartel van de Walle<br> Detecting Rumours in Disasters: An Imbalanced Learning Approach|90|



# Topics of interest

- Learning from imbalanced data
- learning from data streams, including concept drift management
- learning with limited ground truth access
- learning from high dimensional data
- learning with a high number of classes
- learning from massive data, including instance and prototype selection
- learning on the basis of limited data sets, including one-shot learning
- learning from incomplete data
- case studies and real-world applications

# Key dates

| Milestone        | Date           |
| ------------- |:-------------:|
| Paper submission | 13 December 2019 |
| Notification of acceptance of papers | 24 January 2020|
| Camera-ready papers| 28 February 2020|
| Author registration| 24 January – 28 February 2020|
| Conference | 3-5 June 2020|


<!--
# Program

*To be announced.*
-->

<!--
| Tables        | Are           | Cool  |
| ------------- |:-------------:| -----:|
| col 3 is      | right-aligned | $1600 |
| col 2 is      | centered      |   $12 |
| zebra stripes | are neat      |    $1 |
-->

<!--
## Keynote speaker

<div class="picture">
  <img src="acano.jpg">
  <div>
  <h3>Alberto Cano</h3>
  <h5>High Performance Data Mining on GPUs, Hadoop, Spark, and beyond</h5>
  The ever-increasing dimensionality of data poses the main challenge to the scalability of data mining algorithms to run in reasonable time. Parallel and distributed architectures, particularly based on GPUs and the MapReduce model on Apache Hadoop or Spark, have become popular approaches to alleviate the prohibitive runtimes of machine learning algorithms on big data. Not only does the size of data increases the computational complexity but also the emergence of new data-level difficulties and calls for novel learning paradigms. Learning from imbalanced, high-dimensional, data streams with concept drift, or multi-label, to name a few, increase the complexity of algorithms to model such massive data accurately. Therefore, there is a need of new approaches to keep up with the increasing complexity and size of learning from difficult data. This talk reviews advances on the scalability of data mining in recent years and discusses the open issues and future lines of research.

  </div>
</div>

<div class='cleaner'></div>
-->

# Program committee

<ul>
{% assign sorted = (site.data.pc | sort: 'last') %}
{% for person in sorted %}
<li>
    {{ person.first }} {{person.last}}, <em>{{person.university}}, {{person.country}}</em>
</li>
{% endfor %}
</ul>


# Organization commitee

{% assign sorted = (site.data.oc) %}
{% for person in sorted %}
<div class="pictureoc">
  <img src="{{person.img}}.jpg">
  <div>
  {{ person.first }} {{person.last}}, <em>{{person.university}}, {{person.country}}</em>
  </div>
</div>
<div class='cleaner'></div>
{% endfor %}

<br><br>

<center>
<a href="https://kssk.pwr.edu.pl">
<img src="kssk.png">
</a>
</center>

<!--
---


Polar Bear supports GFM!
The following text has been taken from [this page](https://github.com/adam-p/markdown-here/wiki/Markdown-Here-Cheatsheet).

# H1
## H2
### H3
#### H4
##### H5
###### H6


Emphasis, aka italics, with *asterisks* or _underscores_.

Strong emphasis, aka bold, with **asterisks** or __underscores__.

Combined emphasis with **asterisks and _underscores_**.

Strikethrough uses two tildes. ~~Scratch this.~~


1. First ordered list item
2. Another item
  * Unordered sub-list.
1. Actual numbers don't matter, just that it's a number
  1. Ordered sub-list
4. And another item.

   Some text that should be aligned with the above item.

* Unordered list can use asterisks
- Or minuses
+ Or pluses


[I'm an inline-style link](https://www.google.com)

[I'm a reference-style link][Arbitrary case-insensitive reference text]

[You can use numbers for reference-style link definitions][1]

Or leave it empty and use the [link text itself]

Some text to show that the reference links can follow later.

[arbitrary case-insensitive reference text]: https://www.mozilla.org
[1]: http://slashdot.org
[link text itself]: http://www.reddit.com



Inline `code` has `back-ticks around` it.



```javascript
var s = "JavaScript syntax highlighting";
alert(s);
```

```python
s = "Python syntax highlighting"
print s
```

```
No language indicated, so no syntax highlighting.
But let's throw in a <b>tag</b>.
```



Colons can be used to align columns.


The outer pipes (|) are optional, and you don't need to make the raw Markdown line up prettily. You can also use inline Markdown.

Markdown | Less | Pretty
--- | --- | ---
*Still* | `renders` | **nicely**
1 | 2 | 3



> Blockquotes are very handy in email to emulate reply text.
> This line is part of the same quote.

Quote break.

> This is a very long line that will still be quoted properly when it wraps. Oh boy let's keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can *put* **Markdown** into a blockquote.
-->
